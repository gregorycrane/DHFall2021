{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 9303 28 85 149 312 33 99 102 119\n",
      "2 10596 53 87 96 225 23 77 25 27\n",
      "3 8406 53 159 15 36 8 30 9 9\n",
      "4 6976 34 129 15 24 6 12 7 11\n",
      "5 7920 25 145 35 78 9 28 3 9\n",
      "6 14178 56 241 40 115 17 60 34 44\n",
      "7 9841 45 156 25 99 12 37 10 25\n",
      "8 5935 32 79 36 115 19 76 19 35\n",
      "9 8521 22 38 36 104 14 81 34 38\n",
      "10 15583 82 228 117 322 30 173 77 91\n",
      "11 12061 53 247 69 202 22 83 35 48\n",
      "12 11869 49 214 79 175 22 76 29 33\n",
      "13 15318 77 291 84 218 33 118 40 61\n",
      "14 16966 42 417 85 297 15 63 19 19\n",
      "15 24115 84 198 81 218 19 56 39 61\n",
      "16 23613 91 295 45 151 8 49 40 44\n",
      "17 18520 54 138 80 248 22 90 44 51\n",
      "18 14592 71 340 79 165 29 97 33 46\n",
      "19 15062 50 295 72 206 26 93 34 38\n",
      "20 12916 46 182 54 119 12 40 27 29\n",
      "21 21455 88 338 69 250 17 57 62 131\n",
      "22 12107 61 267 53 144 15 36 20 23\n",
      "23 15042 63 248 49 128 13 36 34 43\n",
      "24 17948 67 277 70 273 26 102 35 50\n",
      "25 23405 96 418 107 315 44 166 75 108\n",
      "26 22869 57 221 81 304 37 234 69 89\n",
      "27 19505 75 377 59 205 18 54 39 58\n",
      "28 9031 60 136 20 51 7 15 16 17\n",
      "29 8288 39 195 52 116 17 45 5 5\n",
      "30 15441 60 264 106 343 24 143 50 56\n",
      "31 24108 118 364 112 398 31 204 66 78\n",
      "32 11993 84 273 59 167 22 68 17 22\n",
      "33 7093 46 154 56 165 19 46 20 22\n",
      "34 10645 41 197 62 190 33 77 28 38\n",
      "35 11493 65 249 75 237 24 106 36 42\n",
      "36 18907 100 422 98 387 36 125 37 42\n",
      "37 12651 68 134 70 182 27 77 52 70\n",
      "38 22290 77 244 113 408 43 302 117 180\n",
      "39 10736 62 202 72 180 28 120 32 36\n",
      "40 21579 112 381 133 330 36 125 72 89\n",
      "41 26585 80 467 121 497 31 264 65 105\n",
      "42 16695 70 211 129 382 44 213 70 116\n",
      "43 17923 85 296 115 359 31 177 58 69\n",
      "44 22217 97 254 39 97 25 111 36 54\n",
      "45 13304 54 200 78 226 22 133 45 71\n",
      "46 19255 80 347 131 376 30 185 60 113\n",
      "47 23709 131 450 101 394 43 181 107 178\n",
      "48 30298 172 644 97 276 48 225 65 101\n",
      "49 22307 102 316 112 386 39 226 100 155\n",
      "50 29701 69 399 70 348 43 189 107 261\n",
      "51 31576 104 371 177 608 50 392 149 351\n",
      "52 19928 91 186 152 425 53 238 127 250\n",
      "53 15144 87 191 83 240 40 163 69 88\n",
      "54 5849 43 84 46 85 20 62 34 47\n",
      "55 10513 46 90 79 200 43 177 72 120\n",
      "56 17753 90 291 94 405 49 293 65 104\n",
      "57 11620 53 129 90 262 42 144 71 150\n",
      "58 20931 74 235 125 395 38 173 79 155\n",
      "59 14666 81 213 104 363 33 163 74 121\n",
      "60 16074 76 188 62 211 29 198 66 109\n",
      "61 14205 81 209 95 311 37 176 81 140\n",
      "62 11039 54 181 71 164 24 114 39 66\n",
      "63 9431 34 132 39 94 20 95 26 37\n",
      "64 13183 56 197 129 340 53 242 103 171\n",
      "65 13885 48 222 104 305 40 160 76 120\n",
      "66 15751 103 269 77 281 25 198 76 124\n",
      "67 8858 45 131 66 154 27 109 42 63\n",
      "68 16243 54 162 56 172 30 190 49 71\n",
      "69 14082 80 196 56 195 19 62 61 92\n",
      "70 14828 79 243 52 205 15 54 44 77\n",
      "71 7446 65 116 23 70 11 25 37 59\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import plotly.express as px\n",
    "import csv\n",
    "import pandas as pd\n",
    "totlist = []\n",
    "curlist = []\n",
    "\n",
    "f = open('bury-all-pn.xml')\n",
    "\n",
    "# for each chapter in Gibbon track: tokens, persnames, placenames, ethnics, titles, other\n",
    "prevchap = ''\n",
    "chapter_tokens = {}\n",
    "chapter_persnames = {}\n",
    "chapter_placenames = {}\n",
    "chapter_ethnics = {}\n",
    "chapter_names = {}\n",
    "chapter_headers = {}\n",
    "\n",
    "chapter_persnametot = {}\n",
    "chapter_placenametot = {}\n",
    "chapter_ethnictot = {}\n",
    "chapter_nametot = {}\n",
    "\n",
    "work_persnames = {}\n",
    "work_placenames = {}\n",
    "work_ethnics = {}\n",
    "work_names = {}\n",
    "\n",
    "for i in range (0,72):\n",
    "    chapter_tokens[i] = 0\n",
    "    chapter_persnametot[i] = 0\n",
    "    chapter_placenametot[i] = 0\n",
    "    chapter_ethnictot[i] = 0\n",
    "    chapter_nametot[i] = 0\n",
    "    work_persnames[i] = {}\n",
    "\n",
    "curchap = 0\n",
    "for l in f:\n",
    "    if(re.search('<list><item ',l)):\n",
    "        curhead = re.sub('\\n','',l)\n",
    "        curhead = re.sub('</item>\\s*<item ','--',curhead)\n",
    "        curhead = re.sub('<[^>]+>','',curhead)\n",
    "        chapter_headers[curchap+1] = curhead\n",
    "        print(curchap+1,chapter_headers[curchap+1])\n",
    "        \n",
    "    m = re.search('<s xml:id=\"ch([0-9]+)',l)\n",
    "    if(m):\n",
    "        curchap = int(m[1])\n",
    "    else:\n",
    "        continue\n",
    "    if( not curchap == prevchap):\n",
    "        if(work_persnames):\n",
    "            chapter_persnames[prevchap] = work_persnames\n",
    "            chapter_placenames[prevchap] = work_placenames\n",
    "            chapter_names[prevchap] = work_names\n",
    "            chapter_ethnics[prevchap] = work_ethnics\n",
    "        work_persnames = {}\n",
    "        work_placenames = {}\n",
    "        work_names = {}\n",
    "        work_ethnics = {}\n",
    "    prevchap = curchap\n",
    "    \n",
    "        \n",
    "    workl = re.sub('<[^>]+>','',l)\n",
    "    chapter_tokens[curchap] = chapter_tokens[curchap] + len(workl.split()) + 1\n",
    "    l = re.sub('<(surname|forename|addName|genName)[^>]*>([^<]+)</[a-zA-Z]+>','\\g<2>',l)\n",
    "\n",
    "    while(re.search('<persName[^>]*>([^<]+)',l)):\n",
    "        m = re.search('<persName[^>]*>([^<]+)',l)\n",
    "        curname = m[1]\n",
    "        if(curname in work_persnames):\n",
    "            work_persnames[curname] =  work_persnames[curname]  + 1\n",
    "        else:\n",
    "            work_persnames[curname] = 1\n",
    "        chapter_persnametot[curchap] = chapter_persnametot[curchap] + 1\n",
    "        l = re.sub('<persName[^>]*>([^<]+)',' ',l,1)\n",
    "    while(re.search('<placeName[^>]*>([^<]+)',l)):\n",
    "        m = re.search('<placeName[^>]*>([^<]+)',l)\n",
    "        curname = m[1]\n",
    "        if(curname in work_placenames):\n",
    "            work_placenames[curname] =  work_placenames[curname]  + 1\n",
    "        else:\n",
    "            work_placenames[curname] = 1\n",
    "        chapter_placenametot[curchap] = chapter_placenametot[curchap] + 1\n",
    "        l = re.sub('<placeName[^>]*>([^<]+)',' ',l,1)\n",
    "\n",
    "    while(re.search('<name[^>]*>([^<]+)',l)):\n",
    "        m = re.search('<name[^>]*>([^<]+)',l)\n",
    "        curname = m[1]\n",
    "        if(curname in work_names):\n",
    "            work_names[curname] =  work_names[curname]  + 1\n",
    "        else:\n",
    "            work_names[curname] = 1\n",
    "        chapter_nametot[curchap] = chapter_nametot[curchap] + 1\n",
    "        l = re.sub('<name[^>]*>([^<]+)',' ',l,1)\n",
    "    while(re.search('<rs type=\"ethnic[^>]*>([^<]+)',l)):\n",
    "        m = re.search('<rs type=\"ethnic[^>]*>([^<]+)',l)\n",
    "        curname = m[1]\n",
    "        if(curname in work_ethnics):\n",
    "            work_ethnics[curname] =  work_ethnics[curname]  + 1\n",
    "        else:\n",
    "            work_ethnics[curname] = 1\n",
    "        chapter_ethnictot[curchap] = chapter_ethnictot[curchap] + 1\n",
    "        l = re.sub('<rs type=\"ethnic[^>]*>([^<]+)',' ',l,1)\n",
    "chapter_persnames[prevchap] = work_persnames\n",
    "chapter_placenames[prevchap] = work_placenames\n",
    "chapter_ethnics[prevchap] = work_ethnics\n",
    "chapter_names[prevchap] = work_names\n",
    "\n",
    "f.close()\n",
    "\n",
    "chapinfo = []\n",
    "chapstats = []\n",
    "chaplens = []\n",
    "for i in range(1,72):\n",
    "    print(i,chapter_tokens[i],len(chapter_persnames[i]),chapter_persnametot[i],len(chapter_placenames[i]),chapter_placenametot[i],\n",
    "         len(chapter_ethnics[i]),chapter_ethnictot[i],\n",
    "          len(chapter_names[i]),chapter_nametot[i])\n",
    "    chapstats.append([i,chapter_tokens[i],len(chapter_persnames[i]),chapter_persnametot[i],len(chapter_placenames[i]),chapter_placenametot[i],\n",
    "         len(chapter_ethnics[i]),chapter_ethnictot[i],\n",
    "          len(chapter_names[i]),chapter_nametot[i]])\n",
    "    #print(i,chapter_tokens[i],len(chapter_persnames[i]),len(chapter_placenames[i]),chapter_ethnics[i],chapter_names[i])\n",
    "  #chapinfo.append([i,chapter_tokens[i],'Tokens'])\n",
    "    chapinfo.append([i,chapter_tokens[i],len(chapter_persnames[i])/chapter_tokens[i],'Persnames'])\n",
    "    chapinfo.append([i,chapter_tokens[i],chapter_placenametot[i]/chapter_tokens[i],'Placenames'])\n",
    "    chapinfo.append([i,chapter_tokens[i],chapter_ethnictot[i]/chapter_tokens[i],'Ethnics'])\n",
    "    chapinfo.append([i,chapter_tokens[i],chapter_ethnictot[i]/chapter_tokens[i],'Noclass'])\n",
    "    chaplens.append([i,chapter_tokens[i],chapter_tokens[i]])\n",
    "  #chapinfo.append([chapter_persnames[i],chapter_names[i],chapter_ethnics[i],chapter_names[i]])\n",
    "df2 = pd.DataFrame(chapinfo,columns=['Chapter','ChapTokens','Count','Class'])\n",
    "df = pd.DataFrame(chapstats,columns=['Chapter','Tokens','PersClass','PersTok','PlaceClass','PlaceTok','EthClass','EthTok','NameClass','NameTok'])\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Chapter  Tokens  PersClass  PersTok  PlaceClass  PlaceTok  EthClass  \\\n",
      "47       48   30298        172      644          97       276        48   \n",
      "\n",
      "    EthTok  NameClass  NameTok  \n",
      "47     225         65      101  \n"
     ]
    }
   ],
   "source": [
    "print(df[47:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Chapter  Tokens  PersClass  PersTok  PlaceClass  PlaceTok  EthClass  \\\n",
      "25       26   22869         57      221          81       304        37   \n",
      "\n",
      "    EthTok  NameClass  NameTok  \n",
      "25     234         69       89  \n",
      "23405\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f6061d1ff485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcchap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcchap\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchapter_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcchap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchapter_headers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcchap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfoo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 25"
     ]
    }
   ],
   "source": [
    "cchap = 25\n",
    "\n",
    "\n",
    "workdict = chapter_placenames[cchap]\n",
    "print(df[cchap:cchap+1])\n",
    "print(chapter_tokens[cchap])\n",
    "print(chapter_headers[cchap])\n",
    "print(len(workdict))\n",
    "for foo in sorted(workdict,key=workdict.get,reverse=True):\n",
    "    print(workdict[foo],foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "#df = px.data.medals_long()\n",
    "\n",
    "#fig = px.bar(df, x=\"Chapter\", y=\"Count\", color=\"Class\",\n",
    "#             pattern_shape=\"Class\", pattern_shape_sequence=[\".\", \"x\", \"+\"])\n",
    "#fig.show()\n",
    "\n",
    "fig2 = px.bar(df, x=\"Chapter\", y=\"Tokens\", pattern_shape_sequence=[\".\", \"x\", \"+\"])\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
